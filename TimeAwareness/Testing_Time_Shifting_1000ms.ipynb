{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will test the Time-shift 1000\n",
    "- We will use the vanilla model-Baseline (No augmentation)\n",
    "- We will use the 1000ms augmentation model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.core import Permute, Reshape\n",
    "from keras import backend as K\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as img_PIL\n",
    "\n",
    "\n",
    "# random seed.\n",
    "rand_seed = 2\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(rand_seed)\n",
    "from tqdm.keras import TqdmCallback\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y_data):\n",
    "    Mapping=dict()\n",
    "    sub_dirs=['downstair','upstair','run','jump','walk','handwashing','exercise']\n",
    "\n",
    "    categories=7\n",
    "\n",
    "    count=0\n",
    "    for i in sub_dirs:\n",
    "        Mapping[i]=count\n",
    "        count=count+1\n",
    "\n",
    "    y_features2=[]\n",
    "    for i in range(len(y_data)):\n",
    "        Type=y_data[i]\n",
    "        lab=Mapping[Type]\n",
    "        y_features2.append(lab)\n",
    "\n",
    "    y_features=np.array(y_features2)\n",
    "    y_features=y_features.reshape(y_features.shape[0],1)\n",
    "    from keras.utils import to_categorical\n",
    "    y_features = to_categorical(y_features)\n",
    "\n",
    "    return y_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='auto_data/'\n",
    "\n",
    "\n",
    "def get_train_data(path=path):\n",
    "    Train_data=np.load(path+'train_5000.npz')\n",
    "    Features_imu=np.asarray(Train_data['arr_0'],dtype=np.float64)\n",
    "    Labels=Train_data['arr_1']\n",
    "    Features_sound=Train_data['arr_2']\n",
    "\n",
    "    Labels = one_hot_encoding(Labels)\n",
    "    Features_imu = Features_imu.reshape(Features_imu.shape[0],1, Features_imu.shape[1], Features_imu.shape[2]) \n",
    "\n",
    "    return Features_imu,Labels,Features_sound\n",
    "\n",
    "def get_valid_data(path=path):\n",
    "    Train_data=np.load(path+'valid_1000.npz')\n",
    "    Features_imu=np.asarray(Train_data['arr_0'],dtype=np.float64)\n",
    "    Labels=Train_data['arr_1']\n",
    "    Features_sound=Train_data['arr_2']\n",
    "\n",
    "    Labels = one_hot_encoding(Labels)\n",
    "    Features_imu = Features_imu.reshape(Features_imu.shape[0],1, Features_imu.shape[1], Features_imu.shape[2]) \n",
    "\n",
    "    return Features_imu,Labels,Features_sound\n",
    "\n",
    "def get_test_data(path=path):\n",
    "    Train_data=np.load(path+'test_1377.npz')\n",
    "    Features_imu=np.asarray(Train_data['arr_0'],dtype=np.float64)\n",
    "    Labels=Train_data['arr_1']\n",
    "    Features_sound=Train_data['arr_2']\n",
    "\n",
    "    Labels = one_hot_encoding(Labels)\n",
    "    Features_imu = Features_imu.reshape(Features_imu.shape[0],1, Features_imu.shape[1], Features_imu.shape[2]) \n",
    "\n",
    "    return Features_imu,Labels,Features_sound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1, 40, 12) (5000, 7) (5000, 193)\n",
      "Train Classes distribution:  [760. 994. 546. 780. 532. 732. 656.]\n",
      "(1000, 1, 40, 12) (1000, 7) (1000, 193)\n",
      "Valid Classes distribution:  [150. 188. 136. 141.  98. 157. 130.]\n",
      "(1377, 1, 40, 12) (1377, 7) (1377, 193)\n",
      "Test Classes distribution:  [219. 268. 124. 146. 143. 234. 243.]\n"
     ]
    }
   ],
   "source": [
    "Features_imu,Labels,Features_sound = get_train_data()\n",
    "print(Features_imu.shape, Labels.shape, Features_sound.shape)\n",
    "print('Train Classes distribution: ',np.sum(Labels, axis =0))\n",
    "\n",
    "Features_imu2,Labels2,Features_sound2 = get_valid_data()\n",
    "print(Features_imu2.shape, Labels2.shape, Features_sound2.shape)\n",
    "print('Valid Classes distribution: ',np.sum(Labels2, axis =0))\n",
    "\n",
    "Features_imu3,Labels3,Features_sound3 = get_test_data()\n",
    "print(Features_imu3.shape, Labels3.shape, Features_sound3.shape)\n",
    "print('Test Classes distribution: ',np.sum(Labels3, axis =0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'IMU_Audio_Fusion_1000ms'\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Accuracy\n",
    "model.evaluate([Features_sound3,Features_imu3],Labels3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation: All of these test labels are continuous.\n",
    "### Time window used to create a sample: 2 Second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time shifting, our goal is to randomly insert the samples of different continuous windows in between which is to simulate the real-time deployment setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First preprocess the data to get the continuous acc and gyro windows\n",
    "- data ordering: 12 sensors each with 40 samples.\n",
    "- 12 sensors are: acc_right, gyro_right, acc_left, gyro_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data2(path=path):\n",
    "    Train_data=np.load(path+'test_1377.npz')\n",
    "    Features_imu=np.asarray(Train_data['arr_0'],dtype=np.float64)\n",
    "    Labels=Train_data['arr_1']\n",
    "    Features_sound=Train_data['arr_2']\n",
    "    \n",
    "    Features_imu = Features_imu.reshape(Features_imu.shape[0],1, Features_imu.shape[1], Features_imu.shape[2]) \n",
    "\n",
    "    return Features_imu,Labels,Features_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_imu_t1,Labels_t1,Features_sound_t1 = get_test_data2()\n",
    "print(Features_imu_t1.shape, Labels_t1.shape, Features_sound_t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see all of the labels are continuous\n",
    "Labels_t1 = np.array(Labels_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_t1[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting windows of data together with num_windows_together in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 10 second together\n",
    "num_windows_together = 5\n",
    "\n",
    "curr_indx = 0\n",
    "final_indx = Features_imu_t1.shape[0]\n",
    "\n",
    "data_together = []\n",
    "\n",
    "while curr_indx <= final_indx:\n",
    "    IMU_together   = Features_imu_t1[curr_indx:curr_indx+num_windows_together]\n",
    "    sound_together = Features_sound_t1[curr_indx:curr_indx+num_windows_together]\n",
    "    labels_together = Labels_t1[curr_indx:curr_indx+num_windows_together]\n",
    "    \n",
    "    data_together.append([IMU_together,sound_together,labels_together])\n",
    "    \n",
    "    curr_indx = curr_indx+num_windows_together\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we randomly distribute the windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 4\n",
    "from numpy.random import seed\n",
    "seed(rand_seed)\n",
    "\n",
    "ordering = np.arange(len(data_together))\n",
    "np.random.shuffle(ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordering[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we again recreate the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = ordering[0]\n",
    "\n",
    "Features_imu_t1  = data_together[indx][0]\n",
    "Features_sound_t1 = data_together[indx][1]\n",
    "Labels_t1 = data_together[indx][2]\n",
    "\n",
    "\n",
    "#print(Features_imu_t1.shape,Labels_t1.shape,Features_sound_t1.shape)\n",
    "\n",
    "for i in range(1, len(data_together)):\n",
    "    indx = ordering[i]\n",
    "    IMU_together  = data_together[indx][0]\n",
    "    sound_together= data_together[indx][1]\n",
    "    labels_together=data_together[indx][2]\n",
    "    #print(indx, IMU_together.shape,sound_together.shape,labels_together.shape)\n",
    "    Features_imu_t1 = np.concatenate((Features_imu_t1,IMU_together),axis=0)\n",
    "    Labels_t1 = np.concatenate((Labels_t1,labels_together),axis=0)\n",
    "    Features_sound_t1 = np.concatenate((Features_sound_t1,sound_together),axis=0)\n",
    "    #print(indx, IMU_together.shape,sound_together.shape,labels_together.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Features_imu_t1.shape, Labels_t1.shape, Features_sound_t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_t1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_t1 = one_hot_encoding(Labels_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing accuracy on Reshuffled data.\n",
    "## Note: not time errors are introduced so Accuracy should be same as the fusion model on original continuous test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([Features_sound_t1,Features_imu_t1],Labels_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now aggregating the data and doing the timing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_right=[]\n",
    "gyro_right=[]\n",
    "acc_left=[]\n",
    "gyro_left=[]\n",
    "\n",
    "for i in range(Features_imu_t1.shape[0]):\n",
    "    acc_right.append([Features_imu_t1[i,0,:,0],Features_imu_t1[i,0,:,1],Features_imu_t1[i,0,:,2]])\n",
    "    gyro_right.append([Features_imu_t1[i,0,:,3],Features_imu_t1[i,0,:,4],Features_imu_t1[i,0,:,5]])\n",
    "    acc_left.append([Features_imu_t1[i,0,:,6],Features_imu_t1[i,0,:,7],Features_imu_t1[i,0,:,8]])\n",
    "    gyro_left.append([Features_imu_t1[i,0,:,9],Features_imu_t1[i,0,:,10],Features_imu_t1[i,0,:,11]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_right=np.array(acc_right)\n",
    "gyro_right=np.array(gyro_right)\n",
    "acc_left=np.array(acc_left)\n",
    "gyro_left=np.array(gyro_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_right.shape)\n",
    "print(gyro_right.shape)\n",
    "print(acc_left.shape)\n",
    "print(gyro_left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_right_cont= acc_right[0,]\n",
    "gyro_right_cont= gyro_right[0,]\n",
    "\n",
    "acc_left_cont= acc_left[0,]\n",
    "gyro_left_cont= gyro_left[0,]\n",
    "\n",
    "\n",
    "for i in range(1, Features_imu_t1.shape[0]):\n",
    "    #print(i)\n",
    "    acc_right_cont=np.hstack((acc_right_cont,acc_right[i,]))\n",
    "    gyro_right_cont=np.hstack((gyro_right_cont,gyro_right[i,]))\n",
    "    acc_left_cont=np.hstack((acc_left_cont,acc_left[i,]))\n",
    "    gyro_left_cont=np.hstack((gyro_left_cont,gyro_left[i,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_right_cont.shape)\n",
    "print(gyro_right_cont.shape)\n",
    "print(acc_left_cont.shape)\n",
    "print(gyro_left_cont.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now shifting the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining function to do the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sample_shift(shift_samples = 1):\n",
    "    sample_size = 40 #need to be 40, as decided during training\n",
    "    total_samples = acc_right_cont.shape[1]\n",
    "    \n",
    "    #print(total_samples)\n",
    "    \n",
    "    current_cursor = shift_samples\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    acc_right_pro= np.array(acc_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "\n",
    "    #print(acc_right_pro.shape)\n",
    "\n",
    "    gyro_right_pro= np.array(gyro_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "\n",
    "    acc_left_pro= np.array(acc_left_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "\n",
    "    gyro_left_pro= np.array(gyro_left_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "\n",
    "    #print(np.array(acc_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size]).shape)\n",
    "\n",
    "    while current_cursor<=(total_samples-2*sample_size):\n",
    "        current_cursor = current_cursor + sample_size\n",
    "        #print(current_cursor,\" : \", i)\n",
    "        a=acc_right_pro\n",
    "        b=np.array(acc_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "        acc_right_pro = np.concatenate((a,b),axis=0)\n",
    "\n",
    "\n",
    "        a=gyro_right_pro\n",
    "        b=np.array(gyro_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "        gyro_right_pro = np.concatenate((a,b),axis=0)\n",
    "\n",
    "\n",
    "        a=acc_left_pro\n",
    "        b=np.array(acc_left_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "        #print(a.shape,b.shape)\n",
    "        acc_left_pro = np.concatenate((a,b),axis=0)\n",
    "\n",
    "        a=gyro_left_pro\n",
    "        b=np.array(gyro_left_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "        gyro_left_pro = np.concatenate((a,b),axis=0)\n",
    "        i = i+1\n",
    "        \n",
    "    IMU_processed = np.concatenate((acc_right_pro,gyro_right_pro,acc_left_pro,gyro_left_pro),axis=1)\n",
    "    IMU_processed = IMU_processed[:,np.newaxis,:,:]\n",
    "    IMU_processed = np.swapaxes(IMU_processed,2,3)\n",
    "        \n",
    "    size = IMU_processed.shape[0]\n",
    "        \n",
    "    return Features_sound_t1[:size], IMU_processed ,Labels_t1[:size]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_vanilla = []\n",
    "Accuracy_1000ms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path1 = 'Baseline_IMU_Audio_Fusion'\n",
    "model_path2 = 'IMU_Audio_Fusion_1000ms'\n",
    "\n",
    "from keras.models import load_model\n",
    "model1 = load_model(model_path1)\n",
    "model2 = load_model(model_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for shift in range(41):\n",
    "    Features_sound, IMU ,Labels =  get_data_sample_shift(shift_samples = shift)\n",
    "    evaluation1 = model1.evaluate([Features_sound,IMU],Labels)\n",
    "    Accuracy_vanilla.append(evaluation1[1])\n",
    "    \n",
    "    evaluation2 = model2.evaluate([Features_sound,IMU],Labels)\n",
    "    Accuracy_1000ms.append(evaluation2[1])\n",
    "    \n",
    "    print(\"Shift is:\",shift,evaluation1[1],evaluation2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Accuracy_1000ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "y = np.arange(len(Accuracy_vanilla[:41]))\n",
    "\n",
    "y = y * 50\n",
    "\n",
    "plt.plot(y,(np.array(Accuracy_1000ms[:41])*100))\n",
    "plt.plot(y,(np.array(Accuracy_vanilla[:41])*100))\n",
    "\n",
    "#plt.title('Fused Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Time Synchronization Error (ms)')\n",
    "plt.legend(['Augmentation 1000ms','No Augmentation'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
