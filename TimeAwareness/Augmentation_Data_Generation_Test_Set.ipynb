{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting data to train Audio-IMU fused model\n",
    "\n",
    "# We generate augmented data with\n",
    "- 50ms, 100ms, 150ms, 200ms, 500ms, and 1000ms of shifts.\n",
    "- The shifting is done in the IMU modality.\n",
    "- Training labels are are aligned with the Audio Modality.\n",
    "- The shift are saved in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.core import Permute, Reshape\n",
    "from keras import backend as K\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as img_PIL\n",
    "\n",
    "\n",
    "# random seed.\n",
    "rand_seed = 2\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(rand_seed)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y_data):\n",
    "    Mapping=dict()\n",
    "    sub_dirs=['downstair','upstair','run','jump','walk','handwashing','exercise']\n",
    "\n",
    "    categories=7\n",
    "\n",
    "    count=0\n",
    "    for i in sub_dirs:\n",
    "        Mapping[i]=count\n",
    "        count=count+1\n",
    "\n",
    "    y_features2=[]\n",
    "    for i in range(len(y_data)):\n",
    "        Type=y_data[i]\n",
    "        lab=Mapping[Type]\n",
    "        y_features2.append(lab)\n",
    "\n",
    "    y_features=np.array(y_features2)\n",
    "    y_features=y_features.reshape(y_features.shape[0],1)\n",
    "    from keras.utils import to_categorical\n",
    "    y_features = to_categorical(y_features)\n",
    "\n",
    "    return y_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation: All of these test labels are continuous.\n",
    "### Time window used to create a sample: 2 Second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time shifting, our goal is to use the longest windows and insert time shifting into them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First preprocess the data to get the continuous acc and gyro windows\n",
    "- data ordering: 12 sensors each with 40 samples.\n",
    "- 12 sensors are: acc_right, gyro_right, acc_left, gyro_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/macro/Desktop/UCLA Class/ECE 209AS ML/TimeAwareness/data/'\n",
    "\n",
    "def get_test_data(path=path):\n",
    "    Train_data = np.load(path+'Data_test_71.pkl',allow_pickle=True)\n",
    "    Labels = Train_data[1]\n",
    "    Features_imu = np.asarray(Train_data[0],dtype=np.float64)\n",
    "    Features_audio = Train_data[2]\n",
    "    Features_video = Train_data[3]\n",
    "    \n",
    "    Features_imu = Features_imu.reshape(Features_imu.shape[0],1, Features_imu.shape[1], Features_imu.shape[2])\n",
    "\n",
    "    return Labels,Features_imu,Features_audio,Features_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1377, 1, 40, 12) 1377 (1377, 193)\n"
     ]
    }
   ],
   "source": [
    "Labels_t1,Features_imu_t1,Features_sound_t1,Features_video_t1 = get_test_data()\n",
    "print(Features_imu_t1.shape, len(Labels_t1), Features_sound_t1.shape)\n",
    "#print('Test Classes distribution: ',np.sum(Labels_t1, axis =0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see all of the labels are continuous\n",
    "Labels_t1 = np.array(Labels_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair',\n",
       "       'downstair', 'downstair', 'downstair', 'downstair', 'downstair'],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels_t1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_labels(y_data):\n",
    "    Mapping=dict()\n",
    "    sub_dirs=['downstair','upstair','run','jump','walk','handwashing','exercise']\n",
    "\n",
    "    categories=10\n",
    "\n",
    "    count=0\n",
    "    for i in sub_dirs:\n",
    "        Mapping[i]=count\n",
    "        count=count+1\n",
    "\n",
    "    y_features2=[]\n",
    "    for i in range(len(y_data)):\n",
    "        Type=y_data[i]\n",
    "        lab=Mapping[Type]\n",
    "        y_features2.append(lab)\n",
    "\n",
    "    y_features=np.array(y_features2)\n",
    "    #y_features=y_features.reshape(y_features.shape[0],1)\n",
    "    return y_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 61   5 131  64 105  19  12   2  26 125  47  80  98 114  25  86  16 112\n",
      "  95  24 137  41  34  74   1  18  78  35  29  20 108  60  82   7  10 117\n",
      "  13  15  99  97  27  77  83  43  69  96  92   6  39 119 136  91  63  72\n",
      "   9  14  90 100  31  93  68  11  65   4 107  54  85  37 120  51 111 124\n",
      "  53 116  88  71  70 110  84  75  89  62  67  22  23  76  48  59 113  81\n",
      "  17 123 126  79 118  28 101  33  45  42]\n",
      "138   (138,)\n",
      "---Time 7.679170846939087 seconds ---\n",
      "(1377, 1, 40, 12) (1377,) (1377, 193) (1377, 45, 64, 64, 3)\n",
      "[2 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 6 6 6 6 6 6 6 6 6 6 3 3 3 3 3 3 3\n",
      " 3 3 3 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 6 6 6 6 6 6 6 6 6 6]\n",
      "(1377, 1, 40, 12) (1377,) (1377, 193) (1377, 45, 64, 64, 3)\n",
      "[2 3 3 ... 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "# For 10 second together\n",
    "Labels_t1 = number_labels(Labels_t1)\n",
    "num_windows_together = 10\n",
    "\n",
    "curr_indx = 0\n",
    "final_indx = Features_imu_t1.shape[0]\n",
    "\n",
    "data_together = []\n",
    "\n",
    "while curr_indx <= final_indx:\n",
    "    IMU_together   = Features_imu_t1[curr_indx:curr_indx+num_windows_together]\n",
    "    video_together = Features_video_t1[curr_indx:curr_indx+num_windows_together]\n",
    "    audio_together = Features_sound_t1[curr_indx:curr_indx+num_windows_together]\n",
    "    labels_together = Labels_t1[curr_indx:curr_indx+num_windows_together]\n",
    "    \n",
    "    data_together.append([IMU_together,audio_together,video_together,labels_together])\n",
    "    \n",
    "    curr_indx = curr_indx+num_windows_together\n",
    "    \n",
    "rand_seed = 4\n",
    "from numpy.random import seed\n",
    "seed(rand_seed)\n",
    "\n",
    "ordering = np.arange(len(data_together))\n",
    "np.random.shuffle(ordering)\n",
    "\n",
    "print(ordering[:100])\n",
    "print(len(data_together),' ', ordering.shape)\n",
    "\n",
    "indx = ordering[0]\n",
    "\n",
    "Features_imu_t1  = data_together[indx][0]\n",
    "Features_sound_t1 = data_together[indx][1]\n",
    "Features_video_t1 = data_together[indx][2]\n",
    "Labels_t1 = data_together[indx][3]\n",
    "\n",
    "#print(Features_imu_t1.shape,Labels_t1.shape,Features_sound_t1.shape)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(1, len(data_together)):\n",
    "\n",
    "    indx = ordering[i]\n",
    "    \n",
    "    IMU_together  = data_together[indx][0]\n",
    "    audio_together = data_together[indx][1]\n",
    "    video_together= data_together[indx][2]\n",
    "    labels_together=data_together[indx][3]\n",
    "    \n",
    "    #print(indx, IMU_together.shape,sound_together.shape,labels_together.shape)\n",
    "    \n",
    "    Features_imu_t1 = np.concatenate((Features_imu_t1,IMU_together),axis=0)\n",
    "    Features_sound_t1 = np.concatenate((Features_sound_t1,audio_together),axis=0)\n",
    "    Labels_t1 = np.concatenate((Labels_t1,labels_together),axis=0)\n",
    "    Features_video_t1 = np.concatenate((Features_video_t1,video_together),axis=0)\n",
    "    #print(indx, IMU_together.shape,sound_together.shape,labels_together.shape)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        end_time = time.time()\n",
    "        print(\"---Time %s seconds ---\" % (end_time - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "print(Features_imu_t1.shape,Labels_t1.shape,Features_sound_t1.shape,Features_video_t1.shape)\n",
    "print(Labels_t1[:100])\n",
    "\n",
    "Train_imu=[]\n",
    "Train_labels=[]\n",
    "Train_sound=[]\n",
    "Train_video=[]\n",
    "\n",
    "for i in range(Labels_t1.shape[0]):\n",
    "    Train_imu.append(Features_imu_t1[i])\n",
    "    Train_labels.append(Labels_t1[i])\n",
    "    Train_sound.append(Features_sound_t1[i])\n",
    "    Train_video.append(Features_video_t1[i])\n",
    "    \n",
    "Train_imu=np.array(Train_imu)\n",
    "Train_labels=np.array(Train_labels)\n",
    "Train_sound=np.array(Train_sound)\n",
    "Train_video=np.array(Train_video)\n",
    "\n",
    "print(Train_imu.shape, Train_labels.shape, Train_sound.shape, Train_video.shape)\n",
    "print(Train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this sorting order to recreate the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels_t1 = number_labels(Labels_t1)\n",
    "#print(Labels_t1[:10])\n",
    "\n",
    "# Get a sorting order for the labels\n",
    "#train_order = np.argsort(Labels_t1)\n",
    "# Reorder the labels so they are continuous\n",
    "#Labels_t1[train_order]\n",
    "\n",
    "#Train_imu=[]\n",
    "#Train_labels=[]\n",
    "#Train_sound=[]\n",
    "#Train_video=[]\n",
    "\n",
    "#for i in range(Labels_t1.shape[0]):\n",
    "#    Train_imu.append(Features_imu_t1[train_order[i]])\n",
    "#    Train_labels.append(Labels_t1[train_order[i]])\n",
    "#    Train_sound.append(Features_sound_t1[train_order[i]])\n",
    "#    Train_video.append(Features_video_t1[train_order[i]])\n",
    "    \n",
    "#Train_imu=np.array(Train_imu)\n",
    "#Train_labels=np.array(Train_labels)\n",
    "#Train_sound=np.array(Train_sound)\n",
    "#Train_video=np.array(Train_video)\n",
    "\n",
    "#print(Train_imu.shape, Train_labels.shape, Train_sound.shape, Train_video.shape)\n",
    "#print(Train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Train_labels = to_categorical(Train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing accuracy on Reshuffled data.\n",
    "## Note: not time errors are introduced so Accuracy should be same as the fusion model on original continuous test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now aggregating the data and doing the timing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_right=[]\n",
    "gyro_right=[]\n",
    "acc_left=[]\n",
    "gyro_left=[]\n",
    "\n",
    "for i in range(Train_imu.shape[0]):\n",
    "    acc_right.append([Train_imu[i,0,:,0],Train_imu[i,0,:,1],Train_imu[i,0,:,2]])\n",
    "    gyro_right.append([Train_imu[i,0,:,3],Train_imu[i,0,:,4],Train_imu[i,0,:,5]])\n",
    "    acc_left.append([Train_imu[i,0,:,6],Train_imu[i,0,:,7],Train_imu[i,0,:,8]])\n",
    "    gyro_left.append([Train_imu[i,0,:,9],Train_imu[i,0,:,10],Train_imu[i,0,:,11]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_right=np.array(acc_right)\n",
    "gyro_right=np.array(gyro_right)\n",
    "acc_left=np.array(acc_left)\n",
    "gyro_left=np.array(gyro_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1377, 3, 40)\n",
      "(1377, 3, 40)\n",
      "(1377, 3, 40)\n",
      "(1377, 3, 40)\n"
     ]
    }
   ],
   "source": [
    "print(acc_right.shape)\n",
    "print(gyro_right.shape)\n",
    "print(acc_left.shape)\n",
    "print(gyro_left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "acc_right_cont= acc_right[0,]\n",
    "gyro_right_cont= gyro_right[0,]\n",
    "\n",
    "acc_left_cont= acc_left[0,]\n",
    "gyro_left_cont= gyro_left[0,]\n",
    "\n",
    "\n",
    "for i in range(1, Features_imu_t1.shape[0]):\n",
    "    #print(i)\n",
    "    acc_right_cont=np.hstack((acc_right_cont,acc_right[i,]))\n",
    "    gyro_right_cont=np.hstack((gyro_right_cont,gyro_right[i,]))\n",
    "    acc_left_cont=np.hstack((acc_left_cont,acc_left[i,]))\n",
    "    gyro_left_cont=np.hstack((gyro_left_cont,gyro_left[i,]))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 55080)\n",
      "(3, 55080)\n",
      "(3, 55080)\n",
      "(3, 55080)\n"
     ]
    }
   ],
   "source": [
    "print(acc_right_cont.shape)\n",
    "print(gyro_right_cont.shape)\n",
    "print(acc_left_cont.shape)\n",
    "print(gyro_left_cont.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now shifting the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining function to do the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sample_shift(shift_samples = 1):\n",
    "    sample_size = 40 #need to be 40, as decided during training\n",
    "    total_samples = acc_right_cont.shape[1]\n",
    "    \n",
    "    #print(total_samples)\n",
    "    \n",
    "    current_cursor = shift_samples\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    acc_right_pro= np.array(acc_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "\n",
    "    #print(acc_right_pro.shape)\n",
    "\n",
    "    gyro_right_pro= np.array(gyro_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "\n",
    "    acc_left_pro= np.array(acc_left_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "\n",
    "    gyro_left_pro= np.array(gyro_left_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "\n",
    "    #print(np.array(acc_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size]).shape)\n",
    "\n",
    "    while current_cursor<=(total_samples-2*sample_size):\n",
    "        current_cursor = current_cursor + sample_size\n",
    "        #print(current_cursor,\" : \", i)\n",
    "        a=acc_right_pro\n",
    "        b=np.array(acc_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "        acc_right_pro = np.concatenate((a,b),axis=0)\n",
    "\n",
    "\n",
    "        a=gyro_right_pro\n",
    "        b=np.array(gyro_right_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "        gyro_right_pro = np.concatenate((a,b),axis=0)\n",
    "\n",
    "\n",
    "        a=acc_left_pro\n",
    "        b=np.array(acc_left_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "        #print(a.shape,b.shape)\n",
    "        acc_left_pro = np.concatenate((a,b),axis=0)\n",
    "\n",
    "        a=gyro_left_pro\n",
    "        b=np.array(gyro_left_cont[np.newaxis,:,current_cursor:current_cursor+sample_size])\n",
    "        gyro_left_pro = np.concatenate((a,b),axis=0)\n",
    "        i = i+1\n",
    "        \n",
    "    IMU_processed = np.concatenate((acc_right_pro,gyro_right_pro,acc_left_pro,gyro_left_pro),axis=1)\n",
    "    IMU_processed = IMU_processed[:,np.newaxis,:,:]\n",
    "    IMU_processed = np.swapaxes(IMU_processed,2,3)\n",
    "        \n",
    "    size = IMU_processed.shape[0]    \n",
    "        \n",
    "    return Train_sound[:size], IMU_processed ,Train_labels[:size], Train_video[:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating more training datasets by doing shifting\n",
    "- 1 sample shift = 50 ms timing error.\n",
    "- 20 sample shift = 1000ms timing error.\n",
    "- 1000ms augmentation uses shifts (1,2,10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n",
      "(1376, 193) (1376, 1, 40, 12) (1376, 7) (1376, 45, 64, 64, 3)\n",
      "Train Classes distribution:  [219. 268. 124. 146. 143. 234. 242.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(1,41):\n",
    "    Features_sound_1, IMU_1 ,Labels_1, Features_video_1 =  get_data_sample_shift(shift_samples = i)\n",
    "    \n",
    "#    randomize = np.arange(len(Labels_1))\n",
    "#    np.random.shuffle(randomize)\n",
    "    \n",
    "#    Labels_1 = Labels_1[randomize]\n",
    "#    IMU_1 = IMU_1[randomize]\n",
    "#    Features_sound_1 = Features_sound_1[randomize]\n",
    "#    Features_video_1 = Features_video_1[randomize]\n",
    "    \n",
    "    print(Features_sound_1.shape, IMU_1.shape, Labels_1.shape, Features_video_1.shape)\n",
    "    print(i,' Train Classes distribution: ',np.sum(Labels_1, axis = 0))\n",
    "\n",
    "    path_sample='E:/augmented_data/test_data_'+str(i)+'_shift'\n",
    "    np.savez(path_sample, IMU_1, Labels_1, Features_sound_1, Features_video_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #shift by 1 sample\n",
    "\n",
    "#Features_sound_1, IMU_1 ,Labels_1, Features_video_1 =  get_data_sample_shift(shift_samples = 1)\n",
    "#print(Features_sound_1.shape, IMU_1.shape, Labels_1.shape, Features_video_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#path_1_sample='augmented_data/train_data_1_shift'\n",
    "\n",
    "#np.savez(path_1_sample, IMU_1, Labels_1, Features_sound_1, Features_video_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shift by 2 sample\n",
    "\n",
    "#Features_sound_2, IMU_2 ,Labels_2, Features_video_2 =  get_data_sample_shift(shift_samples = 2)\n",
    "#print(Features_sound_2.shape, IMU_2.shape, Labels_2.shape, Features_video_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#path_2_sample='augmented_data/train_data_2_shift'\n",
    "\n",
    "#np.savez(path_2_sample, IMU_2, Labels_2, Features_sound_2, Features_video_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shift by 10 samples\n",
    "\n",
    "#Features_sound_10, IMU_10 ,Labels_10, Features_video_10 =  get_data_sample_shift(shift_samples = 10)\n",
    "#print(Features_sound_10.shape, IMU_10.shape, Labels_10.shape, Features_video_10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#path1='augmented_data/train_data_10_shift'\n",
    "\n",
    "#np.savez(path1, IMU_10, Labels_10, Features_sound_10, Features_video_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shift by 20 samples\n",
    "\n",
    "#Features_sound_20, IMU_20 ,Labels_20, Features_video_20 =  get_data_sample_shift(shift_samples = 20)\n",
    "#print(Features_sound_20.shape, IMU_20.shape, Labels_20.shape, Features_video_20.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path2='augmented_data/train_data_20_shift'\n",
    "\n",
    "#np.savez(path2, IMU_20, Labels_20, Features_sound_20, Features_video_20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
